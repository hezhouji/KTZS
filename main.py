import akshare as ak
import pandas as pd
import numpy as np
from scipy import stats
import requests
import os
from datetime import datetime, timedelta

# é…ç½®
FEISHU_WEBHOOK = os.getenv("FEISHU_WEBHOOK")
DATA_DIR = "KTZS"
LOG_FILE = "HISTORY_LOG.csv"

def log(msg):
    print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}")

def get_last_workday(target_date):
    """è·å–ç›®æ ‡æ—¥æœŸçš„å‰ä¸€ä¸ªå·¥ä½œæ—¥ï¼ˆè·³è¿‡å‘¨æœ«ï¼‰"""
    dt = target_date - timedelta(days=1)
    while dt.weekday() >= 5:  # 5æ˜¯å‘¨å…­ï¼Œ6æ˜¯å‘¨æ—¥
        dt -= timedelta(days=1)
    return dt

def get_actual_val(date_str):
    path = os.path.join(DATA_DIR, f"{date_str}.txt")
    if os.path.exists(path):
        try:
            with open(path, "r") as f:
                return float(f.read().strip())
        except: return None
    return None

def save_to_history(date_str, raw, bias, final):
    """è®°å½•å†å²ï¼Œç¡®ä¿ä¸é‡å¤"""
    new_line = f"{date_str},{raw:.2f},{bias:.2f},{final:.2f}\n"
    if not os.path.exists(LOG_FILE):
        with open(LOG_FILE, "w") as f:
            f.write("date,raw_score,bias,final_prediction\n")
    
    df = pd.read_csv(LOG_FILE)
    if str(date_str) not in df['date'].values.astype(str):
        with open(LOG_FILE, "a") as f:
            f.write(new_line)
        log(f"âœ… å†å²å­˜è¯: {date_str} æ•°æ®å·²å†™å…¥ CSV")

def calculate_logic(target_date, df_p, df_val, df_bond):
    """å•æ—¥å› å­æ¨¡å‹æ ¸å¿ƒç®—æ³•"""
    try:
        df_curr = df_p[df_p['date'] <= target_date].copy()
        if df_curr.empty: return None
        
        # 1. è‚¡ä»·å¼ºåº¦ (250æ—¥åˆ†ä½)
        h250 = df_curr['close'].rolling(250).max()
        s_score = stats.percentileofscore(df_curr['close']/h250, (df_curr['close']/h250).iloc[-1], kind='weak')
        
        # 2. æˆäº¤é‡èƒ½ (20æ—¥å‡é‡æ¯”)
        v20 = df_curr['volume'].rolling(20).mean()
        v_score = stats.percentileofscore(df_curr['volume']/v20, (df_curr['volume']/v20).iloc[-1], kind='weak')
        
        # 3. è‚¡å€ºæ€§ä»·æ¯” (ERP)
        pe_col = 'å¸‚ç›ˆç‡1' if 'å¸‚ç›ˆç‡1' in df_val.columns else 'å¸‚ç›ˆç‡TTM'
        merged = pd.merge(df_val[['date_key', pe_col]], df_bond[['date_key', 'ä¸­å›½å›½å€ºæ”¶ç›Šç‡10å¹´']], on='date_key')
        merged = merged[merged['date_key'] <= target_date]
        merged['erp'] = (1 / merged[pe_col].astype(float)) - (merged['ä¸­å›½å›½å€ºæ”¶ç›Šç‡10å¹´'].astype(float) / 100)
        # ERPè¶Šé«˜è¶Šææƒ§ï¼Œæ‰€ä»¥å¾—åˆ† = 100 - ç™¾åˆ†ä½
        e_score = 100 - stats.percentileofscore(merged['erp'], merged['erp'].iloc[-1], kind='weak')

        raw = (s_score * 0.4) + (v_score * 0.3) + (e_score * 0.3)
        return round(raw, 2)
    except Exception as e:
        log(f"æ—¥æœŸ {target_date} è®¡ç®—å¤±è´¥: {e}")
        return None

def main():
    today = datetime.now().date()
    # å¦‚æœä»Šå¤©æ˜¯å‘¨æœ«ï¼Œç¨‹åºä¸è¿è¡Œ
    if today.weekday() >= 5:
        log("ä»Šæ—¥ä¸ºå‘¨æœ«ï¼Œä¼‘å¸‚ä¸è¿è¡Œã€‚")
        return

    # 1. é¢„åŠ è½½æ•°æ®
    log("è·å–å…¨é‡é‡‘èæ•°æ®...")
    df_p = ak.stock_zh_index_daily(symbol="sh000300")
    df_p['date'] = pd.to_datetime(df_p['date']).dt.date
    df_val = ak.stock_zh_index_value_csindex(symbol="000300")
    df_val['date_key'] = pd.to_datetime(df_val['æ—¥æœŸ']).dt.date
    df_bond = ak.bond_zh_us_rate()
    df_bond['date_key'] = pd.to_datetime(df_bond['æ—¥æœŸ']).dt.date

    # 2. è¡¥ç®—é€»è¾‘ï¼šæ£€æŸ¥è¿‡å»7å¤©
    log("å¯åŠ¨å†å²è¡¥ç®—è‡ªæ£€...")
    for i in range(7, 0, -1):
        target_day = today - timedelta(days=i)
        if target_day.weekday() >= 5: continue # è·³è¿‡å‘¨æœ«
        
        t_str = target_day.strftime("%Y%m%d")
        actual = get_actual_val(t_str)
        if actual:
            raw = calculate_logic(target_day, df_p, df_val, df_bond)
            if raw: save_to_history(t_str, raw, actual - raw, actual)
        elif i == 1 or (today.weekday() == 0 and i == 3): # æ˜¨å¤©ç¼ºå¤± æˆ– å‘¨ä¸€è¿è¡Œä¸”ä¸Šå‘¨äº”ç¼ºå¤±
            # é£ä¹¦æŠ¥è­¦é€»è¾‘
            requests.post(FEISHU_WEBHOOK, json={
                "msg_type": "text", "content": {"text": f"âš ï¸ ç¼ºå¤±å¯¹æ ‡æ•°æ®: {t_str}.txtï¼Œè¯·åŠæ—¶è¡¥å½•ã€‚"}
            })

    # 3. ä»Šæ—¥é¢„æµ‹
    last_workday = get_last_workday(today)
    yest_actual = get_actual_val(last_workday.strftime("%Y%m%d"))
    
    today_raw = calculate_logic(today, df_p, df_val, df_bond)
    
    if today_raw:
        # å¯»æ‰¾æœ€è¿‘çš„ä¸€ä¸ªåå·®å€¼
        if os.path.exists(LOG_FILE):
            df_h = pd.read_csv(LOG_FILE)
            last_bias = df_h['bias'].iloc[-1] if not df_h.empty else 0
        else: last_bias = 0
        
        final_prediction = round(today_raw + last_bias, 2)
        log(f"ä»Šæ—¥é¢„æµ‹: {final_prediction} (åŸºäºæœ€è¿‘åå·® {last_bias:+.2f})")
        
        # å‘é€é£ä¹¦
        payload = {
            "msg_type": "interactive",
            "card": {
                "header": {"title": {"tag": "plain_text", "content": f"ğŸ“Š æè´ªæŒ‡æ•°é¢„æµ‹ ({today})"}, "template": "blue"},
                "elements": [
                    {"tag": "div", "text": {"tag": "lark_md", "content": f"**ä»Šæ—¥é¢„æµ‹ï¼š{final_prediction}**\nåŸç”Ÿï¼š{today_raw} | ä¿®æ­£ï¼š{last_bias:+.2f}"}},
                    {"tag": "note", "elements": [{"tag": "plain_text", "content": f"å·²è‡ªåŠ¨è·³è¿‡å‘¨æœ«ï¼Œå¯¹æ ‡å‰ä¸€å·¥ä½œæ—¥ï¼š{last_workday}"}]}
                ]
            }
        }
        requests.post(FEISHU_WEBHOOK, json=payload)

if __name__ == "__main__":
    main()