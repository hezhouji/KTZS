import akshare as ak
import pandas as pd
import numpy as np
from scipy import stats
from scipy.optimize import minimize
import requests
import os
from datetime import datetime, timedelta

# --- åŸºç¡€é…ç½® ---
FEISHU_WEBHOOK = os.getenv("FEISHU_WEBHOOK")
DATA_DIR = "KTZS"
LOG_FILE = "HISTORY_LOG.csv"

def log(msg):
    print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}")

def is_workday(d_obj):
    return d_obj.weekday() < 5

def normalize_date(d_val):
    """å¼ºåˆ¶æ¸…æ´—æ—¥æœŸæ ¼å¼"""
    if not d_val or pd.isna(d_val): return None
    s = str(d_val).replace(".txt", "").replace("å¹´", "-").replace("æœˆ", "-").replace("æ—¥", "")
    for fmt in ("%Y-%m-%d", "%Y%m%d"):
        try:
            return datetime.strptime(s, fmt).date()
        except: continue
    return None

def get_actual_val(date_obj):
    """ä» KTZS æ–‡ä»¶å¤¹åŒ¹é…è¡¥å½•çš„çœŸå®å€¼"""
    target = date_obj.strftime("%Y%m%d")
    if not os.path.exists(DATA_DIR): return None
    for f in os.listdir(DATA_DIR):
        if target in f and f.endswith(".txt"):
            try:
                with open(os.path.join(DATA_DIR, f), "r") as file:
                    return float(file.read().strip())
            except: pass
    return None

def calculate_factors(target_date, df_p_all, df_val_all, df_bond_all):
    """ä¸¥æ ¼å†å²åˆ‡ç‰‡è®¡ç®—"""
    try:
        df_p = df_p_all[df_p_all['date'] <= target_date].copy()
        df_val = df_val_all[df_val_all['date_key'] <= target_date].copy()
        df_bond = df_bond_all[df_bond_all['date_key'] <= target_date].copy()
        
        if len(df_p) < 30: return [50.0] * 6

        def get_p(series, cur, inv=False):
            series = pd.to_numeric(series, errors='coerce').dropna()
            if series.empty or np.isnan(cur): return 50.0
            p = stats.percentileofscore(series, cur, kind='weak')
            return float(100 - p if inv else p)

        # f1: æ³¢åŠ¨ | f2: æˆäº¤é‡ | f3: å¼ºåº¦
        vol = df_p['close'].pct_change().rolling(20).std()
        f1 = get_p(vol, vol.iloc[-1], inv=True)
        v20 = df_p['volume'].rolling(20).mean()
        f2 = get_p(df_p['volume'] / v20, (df_p['volume'] / v20).iloc[-1])
        h250 = df_p['close'].rolling(250).max()
        f3 = get_p(df_p['close'] / h250, (df_p['close'] / h250).iloc[-1])
        f4 = 50.0 # æ¨¡æ‹ŸåŸºå·®
        
        # f5: é¿é™©å¤©å ‚ (ERP) - æ·±åº¦å…¼å®¹æ€§ä¿®å¤
        pe_val = None
        for col in ['å¸‚ç›ˆç‡1', 'å¸‚ç›ˆç‡TTM', 'å¸‚ç›ˆç‡']:
            if col in df_val.columns:
                pe_val = pd.to_numeric(df_val[col], errors='coerce')
                break
        bond_rate = None
        for col in ['ä¸­å›½å›½å€ºæ”¶ç›Šç‡10å¹´', 'rate', 'æ”¶ç›Šç‡']:
            if col in df_bond.columns:
                bond_rate = pd.to_numeric(df_bond[col], errors='coerce') / 100
                break

        if pe_val is not None and bond_rate is not None:
            erp_series = (1 / pe_val) - bond_rate
            f5 = get_p(erp_series, erp_series.iloc[-1], inv=True)
        else:
            f5 = 50.0

        f6 = 50.0 # æ æ†æ¨¡æ‹Ÿ
        return [round(x, 2) for x in [f1, f2, f3, f4, f5, f6]]
    except Exception as e:
        log(f"å› å­è®¡ç®—å¤±è´¥: {e}")
        return [50.0] * 6

def main():
    log("=== å¯åŠ¨ AI é¢„æµ‹ç³»ç»Ÿ (è‡ªåŠ¨æ¸…ç†å¹¶é‡æ„æ¨¡å¼) ===")
    
    # ã€æ–°å¢é€»è¾‘ã€‘æ¯æ¬¡è¿è¡Œå‰è‡ªåŠ¨ç‰©ç†åˆ é™¤æ—§è¡¨æ ¼
    if os.path.exists(LOG_FILE):
        os.remove(LOG_FILE)
        log(f"å·²åˆ é™¤æ—§è¡¨æ ¼: {LOG_FILE}")
    
    today = datetime.now().date()
    cols = ["date", "f1", "f2", "f3", "f4", "f5", "f6", "predict", "actual", "bias"]
    df_log = pd.DataFrame(columns=cols)

    # 1. æŠ“å–å…¨é‡å¸‚åœºæ•°æ®
    log("æ­£åœ¨è·å–æœ€æ–°å¸‚åœºæ•°æ®...")
    df_p = ak.stock_zh_index_daily(symbol="sh000300")
    df_p['date'] = pd.to_datetime(df_p['date']).dt.date
    df_val = ak.stock_zh_index_value_csindex(symbol="000300")
    df_val['date_key'] = pd.to_datetime(df_val['æ—¥æœŸ']).dt.date
    df_bond = ak.bond_zh_us_rate()
    df_bond['date_key'] = pd.to_datetime(df_bond['æ—¥æœŸ']).dt.date

    # 2. é‡æ–°æ„å»ºå†å²æ•°æ® (å›æº¯ 14 å¤©)
    log("æ ¹æ® KTZS è¡¥å½•æ–‡ä»¶é‡æ–°æ„å»ºå†å²è®°å¿†...")
    for i in range(14, 0, -1):
        d = today - timedelta(days=i)
        if not is_workday(d): continue
        act = get_actual_val(d)
        if act is not None:
            d_str = d.strftime("%Y-%m-%d")
            fs = calculate_factors(d, df_p, df_val, df_bond)
            p_raw = round(sum(fs) / 6, 2)
            df_log.loc[len(df_log)] = [d_str] + fs + [p_raw, act, round(act - p_raw, 2)]

    # 3. åŠ¨æ€æƒé‡è¿›åŒ–
    weights = np.array([1/6] * 6)
    if len(df_log) >= 5:
        X = df_log[['f1', 'f2', 'f3', 'f4', 'f5', 'f6']].values
        y = df_log['actual'].values
        res = minimize(lambda w: np.sum((X @ w - y)**2), weights, bounds=[(0.05, 0.4)]*6, constraints={'type':'eq','fun':lambda w: sum(w)-1})
        if res.success: weights = res.x

    # 4. ä»Šæ—¥é¢„æµ‹
    today_factors = calculate_factors(today, df_p, df_val, df_bond)
    today_raw = round(sum(f * w for f, w in zip(today_factors, weights)), 2)
    
    # ä¿®æ­£å€¼è®¡ç®—
    bias_fix = 0.0
    if not df_log.empty:
        last_b = df_log.iloc[-1]['bias']
        if not np.isnan(last_b): bias_fix = last_b
    
    final_predict = round(today_raw + bias_fix, 2)

    # å†™å…¥ä»Šæ—¥è¡Œå¹¶ä¿å­˜
    t_str = today.strftime("%Y-%m-%d")
    df_log.loc[len(df_log)] = [t_str] + today_factors + [today_raw, np.nan, np.nan]
    df_log.sort_values('date').to_csv(LOG_FILE, index=False)
    log(f"æ–°è¡¨æ ¼å·²ç”Ÿæˆï¼Œä»Šæ—¥é¢„æµ‹: {final_predict}")

    # 5. é£ä¹¦å¡ç‰‡æ¨é€
    w_info = " | ".join([f"{n}:{w:.0%}" for n, w in zip(["æ³¢åŠ¨","é‡èƒ½","å¼ºåº¦","æœŸè´§","é¿é™©","æ æ†"], weights)])
    payload = {
        "msg_type": "interactive",
        "card": {
            "header": {"title": {"tag": "plain_text", "content": f"ğŸ¯ æè´ª AI æŒ‡æ•°é¢„æµ‹æŠ¥å‘Š ({today})"}, "template": "purple"},
            "elements": [
                {"tag": "div", "text": {"tag": "lark_md", "content": f"**ä»Šæ—¥å»ºè®®å€¼ï¼š{final_predict}**\nåŸç”Ÿåˆ†ï¼š{today_raw} | ä¿®æ­£å€¼ï¼š{bias_fix:+.1f}\n\nğŸ“Š **AI æƒé‡è¿›åŒ–è¯¦æƒ…ï¼š**\n{w_info}"}},
                {"tag": "hr"},
                {"tag": "note", "elements": [{"tag": "plain_text", "content": f"ç»´åº¦åˆ†: {' / '.join(map(str, today_factors))} | æœç´¢è¯: æè´ª"}]}
            ]
        }
    }
    
    if FEISHU_WEBHOOK:
        r = requests.post(FEISHU_WEBHOOK, json=payload)
        log(f"æ¨é€çŠ¶æ€: {r.status_code}")

if __name__ == "__main__":
    main()