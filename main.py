import akshare as ak
import pandas as pd
import numpy as np
from scipy import stats
from scipy.optimize import minimize
import requests
import os
from datetime import datetime, timedelta

# --- åŸºç¡€é…ç½® ---
FEISHU_WEBHOOK = os.getenv("FEISHU_WEBHOOK")
DATA_DIR = "KTZS"
LOG_FILE = "HISTORY_LOG.csv"

def log(msg):
    print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}")

def is_workday(date_obj):
    return date_obj.weekday() < 5

def parse_date(d_str):
    """å¼ºåˆ¶å°†å„ç§æ—¥æœŸæ ¼å¼è½¬æ¢ä¸ºæ ‡å‡† YYYY-MM-DD"""
    d_str = str(d_str).replace(".txt", "").replace("å¹´", "-").replace("æœˆ", "-").replace("æ—¥", "")
    for fmt in ("%Y-%m-%d", "%Y%m%d"):
        try:
            return datetime.strptime(d_str, fmt).date()
        except: continue
    return None

def get_actual_val(date_obj):
    """æœç´¢æ–‡ä»¶å¤¹ä¸­åŒ¹é…æ—¥æœŸçš„æ•°å€¼"""
    target = date_obj.strftime("%Y%m%d")
    if not os.path.exists(DATA_DIR): return None
    for f in os.listdir(DATA_DIR):
        if target in f and f.endswith(".txt"):
            try:
                with open(os.path.join(DATA_DIR, f), "r") as file:
                    return float(file.read().strip())
            except: pass
    return None

# --- å…­ç»´åº¦æ ¸å¿ƒè®¡ç®—ï¼ˆå¸¦ä¸¥æ ¼åˆ‡ç‰‡ï¼‰ ---
def calculate_six_factors(target_date, df_p_all, df_val_all, df_bond_all):
    try:
        # ã€å…³é”®ä¿®å¤ã€‘åªä¿ç•™ç›®æ ‡æ—¥æœŸåŠä¹‹å‰çš„æ•°æ®
        df_p = df_p_all[df_p_all['date'] <= target_date].copy()
        df_val = df_val_all[df_val_all['date_key'] <= target_date].copy()
        df_bond = df_bond_all[df_bond_all['date_key'] <= target_date].copy()
        
        if len(df_p) < 30: return [50.0]*6

        def get_p(series, current, reverse=False):
            p = stats.percentileofscore(series.dropna(), current, kind='weak')
            return float(100 - p if reverse else p)

        # 1. æ³¢åŠ¨ (20æ—¥)
        v = df_p['close'].pct_change().rolling(20).std()
        f1 = get_p(v, v.iloc[-1], reverse=True)

        # 2. æ€»æˆäº¤é‡ (20æ—¥æ¯”)
        v20 = df_p['volume'].rolling(20).mean()
        f2 = get_p(df_p['volume']/v20, (df_p['volume']/v20).iloc[-1])

        # 3. è‚¡ä»·å¼ºåº¦ (250æ—¥ä½ç½®)
        h250 = df_p['close'].rolling(250).max()
        f3 = get_p(df_p['close']/h250, (df_p['close']/h250).iloc[-1])

        # 4. å‡è´´æ°´ (ç®€å•æ¨¡æ‹ŸåŸºå·®)
        f4 = 50.0 # æš‚æ— ç¨³å®šå†å²åˆ‡ç‰‡æ¥å£æ—¶è®¾ä¸ºä¸­æ€§

        # 5. é¿é™©å¤©å ‚ (ERP)
        pe_col = 'å¸‚ç›ˆç‡1' if 'å¸‚ç›ˆç‡1' in df_val_all.columns else 'å¸‚ç›ˆç‡TTM'
        erp = (1/df_val[pe_col].astype(float)) - (df_bond['ä¸­å›½å›½å€ºæ”¶ç›Šç‡10å¹´'].astype(float)/100)
        f5 = get_p(erp, erp.iloc[-1], reverse=True)

        # 6. æ æ†æ°´å¹³ (æ¨¡æ‹Ÿèèµ„å¼ºåº¦)
        f6 = 50.0 

        return [round(x, 2) for x in [f1, f2, f3, f4, f5, f6]]
    except:
        return [50.0]*6

def main():
    log("=== å¯åŠ¨æ•°æ®æ ‡å‡†åŒ–è‡ªå­¦ä¹ ç³»ç»Ÿ ===")
    today = datetime.now().date()
    
    # è·å–å…¨é‡æ•°æ®ç”¨äºåˆ‡ç‰‡
    df_p = ak.stock_zh_index_daily(symbol="sh000300")
    df_p['date'] = pd.to_datetime(df_p['date']).dt.date
    df_val = ak.stock_zh_index_value_csindex(symbol="000300")
    df_val['date_key'] = pd.to_datetime(df_val['æ—¥æœŸ']).dt.date
    df_bond = ak.bond_zh_us_rate()
    df_bond['date_key'] = pd.to_datetime(df_bond['æ—¥æœŸ']).dt.date

    # 1. åˆå§‹åŒ–æˆ–æ¸…æ´— CSV
    cols = ["date","f1","f2","f3","f4","f5","f6","predict","actual","bias"]
    if os.path.exists(LOG_FILE):
        df_log = pd.read_csv(LOG_FILE)
        df_log['date'] = df_log['date'].apply(lambda x: parse_date(x).strftime("%Y-%m-%d") if parse_date(x) else x)
        df_log = df_log.drop_duplicates(subset=['date'], keep='last')
    else:
        df_log = pd.DataFrame(columns=cols)

    # 2. è¡¥å…¨å†å²ä¸é‡ç®—ï¼ˆè¿‡å» 14 å¤©ï¼‰
    for i in range(14, 0, -1):
        d = today - timedelta(days=i)
        if not is_workday(d): continue
        
        act = get_actual_val(d)
        d_str = d.strftime("%Y-%m-%d")
        
        # å¦‚æœæœ‰å®é™…å€¼ä¸”(è®°å½•ç¼ºå¤±æˆ–æ•°å€¼æ²¡ç®—å¯¹)ï¼Œåˆ™é‡ç®—
        if act:
            f_scores = calculate_six_factors(d, df_p, df_val, df_bond)
            p_val = sum(f_scores)/6
            new_data = [d_str] + f_scores + [round(p_val, 2), act, round(act-p_val, 2)]
            df_log = df_log[df_log['date'] != d_str] # åˆ æ—§
            df_log.loc[len(df_log)] = new_data

    # 3. æƒé‡åŠ¨æ€ä¼˜åŒ–ï¼ˆåŸºäºè¿‡å» 7 æ¡å®é™…è®°å½•ï¼‰
    weights = np.array([1/6]*6)
    df_learn = df_log.dropna(subset=['actual'])
    if len(df_learn) >= 7:
        recent = df_learn.tail(7)
        X = recent[['f1','f2','f3','f4','f5','f6']].values
        y = recent['actual'].values
        def obj(w): return np.sum((X @ w - y)**2)
        res = minimize(obj, weights, bounds=[(0.05, 0.4)]*6, constraints={'type':'eq','fun':lambda w: sum(w)-1})
        if res.success: weights = res.x

    # 4. ä»Šæ—¥é¢„æµ‹
    today_f = calculate_six_factors(today, df_p, df_val, df_bond)
    today_p = sum(f * w for f, w in zip(today_f, weights))
    
    # å†™å…¥ä»Šæ—¥è¡Œï¼ˆå¾…åç»­å¡«å…¥å®é™…å€¼ï¼‰
    t_str = today.strftime("%Y-%m-%d")
    df_log = df_log[df_log['date'] != t_str]
    df_log.loc[len(df_log)] = [t_str] + today_f + [round(today_p, 2), np.nan, np.nan]
    
    # ä¿å­˜ç»“æœ
    df_log.sort_values('date').to_csv(LOG_FILE, index=False)
    log(f"ä»Šæ—¥é¢„æµ‹å®Œæˆ: {today_p:.2f}")

    # 5. æ¨é€é£ä¹¦ (æ¯ 7 å¤©é™„å¸¦æŠ¥å‘Š)
    report = ""
    if len(df_learn) % 7 == 0 and len(df_learn) > 0:
        names = ["æ³¢åŠ¨", "é‡èƒ½", "å¼ºåº¦", "æœŸè´§", "é¿é™©", "æ æ†"]
        w_list = [f"{n}:{w:.0%}" for n, w in zip(names, weights)]
        report = "\n\nğŸ“Š **æœ¬å‘¨æƒé‡è¿›åŒ–ç»“æœ**ï¼š\n" + " | ".join(w_list)

    payload = {
        "msg_type": "interactive",
        "card": {
            "header": {"title": {"tag": "plain_text", "content": f"ğŸ¯ æè´ª AI é¢„æµ‹ ({today})"}, "template": "purple"},
            "elements": [
                {"tag": "div", "text": {"tag": "lark_md", "content": f"**æœ€ç»ˆé¢„æµ‹å€¼ï¼š{today_p:.2f}**\n*å·²æ ¹æ®å†å²éŸ­åœˆæ•°æ®å®Œæˆæƒé‡å¯¹é½*{report}"}},
                {"tag": "note", "elements": [{"tag": "plain_text", "content": f"ç»´åº¦åˆ†: {' / '.join(map(str, today_f))}"}]}
            ]
        }
    }
    requests.post(FEISHU_WEBHOOK, json=payload)

if __name__ == "__main__":
    main()