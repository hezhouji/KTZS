import akshare as ak
import pandas as pd
import numpy as np
from scipy import stats
from scipy.optimize import minimize
import requests
import os
import time
from datetime import datetime, timedelta

# --- Âü∫Á°ÄÈÖçÁΩÆ ---
FEISHU_WEBHOOK = os.getenv("FEISHU_WEBHOOK")
DATA_DIR = "KTZS"
LOG_FILE = "HISTORY_LOG.csv"

def log(msg):
    print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}")

def is_workday(d_obj):
    return d_obj.weekday() < 5

def get_actual_val(date_obj):
    target = date_obj.strftime("%Y%m%d")
    if not os.path.exists(DATA_DIR): return None
    for f in os.listdir(DATA_DIR):
        if target in f and f.endswith(".txt"):
            try:
                with open(os.path.join(DATA_DIR, f), "r") as file:
                    return float(file.read().strip())
            except: pass
    return None

# --- Êï∞ÊçÆËé∑ÂèñÊ®°Âùó (Â¢ûÂº∫Á®≥ÂÅ•ÊÄß) ---
def fetch_data_with_retry(func, **kwargs):
    for _ in range(3):
        try:
            df = func(**kwargs)
            if df is not None and not df.empty:
                return df
        except:
            time.sleep(1)
    return pd.DataFrame()

def main():
    log("=== ÂêØÂä® AI ÂÆûÁõòÈ¢ÑÊµãÁ≥ªÁªü (‰øÆÂ§çÁâà) ===")
    
    # 0. Ê∏ÖÁêÜÊóßÊï∞ÊçÆÔºåÁ°Æ‰øùÈáçÊñ∞ËÆ°ÁÆó
    if os.path.exists(LOG_FILE):
        try: os.remove(LOG_FILE)
        except: pass

    today = datetime.now().date()
    
    # --- 1. Ëé∑ÂèñÂÖ®Áª¥Â∫¶ÁúüÂÆûÊï∞ÊçÆ (Â∏¶ÂºÇÂ∏∏Êã¶Êà™) ---
    
    # [f1, f2, f3] Áé∞Ë¥ßÊï∞ÊçÆ
    log("1/4 Ëé∑ÂèñÊ≤™Ê∑±300Áé∞Ë¥ßÊï∞ÊçÆ...")
    try:
        df_p = fetch_data_with_retry(ak.stock_zh_index_daily, symbol="sh000300")
        df_p['date'] = pd.to_datetime(df_p['date']).dt.date
    except Exception as e:
        log(f"‚ö†Ô∏è Áé∞Ë¥ßÊï∞ÊçÆËé∑ÂèñÂ§±Ë¥•: {e}")
        df_p = pd.DataFrame()

    # [f4] ÊúüË¥ßÊï∞ÊçÆ
    log("2/4 Ëé∑ÂèñËÇ°ÊåáÊúüË¥ß(IF)Êï∞ÊçÆ...")
    try:
        df_fut = fetch_data_with_retry(ak.futures_zh_daily_sina, symbol="IF0")
        if not df_fut.empty:
            df_fut['date'] = pd.to_datetime(df_fut['date']).dt.date
    except:
        df_fut = pd.DataFrame()

    # [f5] ‰º∞ÂÄº‰∏éÂõΩÂÄ∫
    log("3/4 Ëé∑Âèñ‰º∞ÂÄº‰∏éÂõΩÂÄ∫Êï∞ÊçÆ...")
    try:
        df_val = fetch_data_with_retry(ak.stock_zh_index_value_csindex, symbol="000300")
        df_val['date_key'] = pd.to_datetime(df_val['Êó•Êúü']).dt.date
        df_bond = fetch_data_with_retry(ak.bond_zh_us_rate)
        df_bond['date_key'] = pd.to_datetime(df_bond['Êó•Êúü']).dt.date
    except:
        df_val, df_bond = pd.DataFrame(), pd.DataFrame()

    # [f6] ËûçËµÑËûçÂà∏ (‰øÆÂ§çÁÇπÔºöÊîπÁî®‰∏ä‰∫§ÊâÄÊ±áÊÄªÊé•Âè£)
    log("4/4 Ëé∑ÂèñËûçËµÑËûçÂà∏Êï∞ÊçÆ (SSE)...")
    try:
        # ‰ΩøÁî® ak.stock_margin_sse_summary Êõø‰ª£‰∏çÁ®≥ÂÆöÁöÑ exchange Êé•Âè£
        df_margin = fetch_data_with_retry(ak.stock_margin_sse_summary)
        if not df_margin.empty:
            # Áªü‰∏ÄÂàóÂêçÊ†ºÂºè
            df_margin.rename(columns={"‰ø°Áî®‰∫§ÊòìÊó•Êúü": "date_key", "ËûçËµÑ‰ΩôÈ¢ù": "rzye"}, inplace=True)
            df_margin['date_key'] = pd.to_datetime(df_margin['date_key']).dt.date
    except Exception as e:
        log(f"‚ö†Ô∏è ËûçËµÑÊï∞ÊçÆËé∑ÂèñÂ§±Ë¥•: {e}")
        df_margin = pd.DataFrame()

    # --- 2. ÂÆö‰πâÂõ†Â≠êËÆ°ÁÆóÂºïÊìé ---
    def calculate_factors(target_date, _df_p, _df_fut, _df_val, _df_bond, _df_margin):
        try:
            # Âü∫Á°ÄÊï∞ÊçÆÂàáÁâá
            if _df_p.empty: return [50.0]*6
            cut_p = _df_p[_df_p['date'] <= target_date].copy()
            if len(cut_p) < 30: return [50.0] * 6

            def get_score(series, current_val, invert=False):
                s = pd.to_numeric(series, errors='coerce').dropna()
                if len(s) < 10 or pd.isna(current_val): return 50.0
                # ÂèñÊúÄËøë3Âπ¥Êï∞ÊçÆ‰Ωú‰∏∫ÂàÜ‰ΩçÂèÇËÄÉ
                s_window = s.tail(750) 
                p = stats.percentileofscore(s_window, current_val, kind='weak')
                return float(100 - p if invert else p)

            # [f1] Ê≥¢Âä®Áéá
            vol = cut_p['close'].pct_change().rolling(20).std()
            f1 = get_score(vol, vol.iloc[-1], invert=True)

            # [f2] Êàê‰∫§Èáè
            vol_ratio = cut_p['volume'] / cut_p['volume'].rolling(20).mean()
            f2 = get_score(vol_ratio, vol_ratio.iloc[-1], invert=False)

            # [f3] ‰ª∑Ê†ºÂº∫Â∫¶
            high_250 = cut_p['close'].rolling(250).max()
            f3 = get_score(cut_p['close'] / high_250, (cut_p['close'] / high_250).iloc[-1], invert=False)

            # [f4] ÂçáË¥¥Ê∞¥
            f4 = 50.0
            if not _df_fut.empty:
                cut_f = _df_fut[_df_fut['date'] <= target_date].copy()
                merged = pd.merge(cut_p[['date','close']], cut_f[['date','close']], on='date', suffixes=('_spot', '_fut'))
                if not merged.empty:
                    basis = (merged['close_fut'] - merged['close_spot']) / merged['close_spot']
                    f4 = get_score(basis, basis.iloc[-1], invert=False)

            # [f5] ËÇ°ÂÄ∫ÊÄß‰ª∑ÊØî ERP
            f5 = 50.0
            if not _df_val.empty and not _df_bond.empty:
                pe_col = next((c for c in _df_val.columns if 'Â∏ÇÁõàÁéá' in c and 'TTM' in c), None)
                if not pe_col: pe_col = next((c for c in _df_val.columns if 'Â∏ÇÁõàÁéá' in c), None)
                rate_col = next((c for c in _df_bond.columns if '10Âπ¥' in c), None)
                
                if pe_col and rate_col:
                    cut_v = _df_val[_df_val['date_key'] <= target_date].set_index('date_key')[[pe_col]]
                    cut_b = _df_bond[_df_bond['date_key'] <= target_date].set_index('date_key')[[rate_col]]
                    erp_df = cut_v.join(cut_b).dropna()
                    if not erp_df.empty:
                        erp = (1 / pd.to_numeric(erp_df[pe_col])) - (pd.to_numeric(erp_df[rate_col]) / 100)
                        f5 = get_score(erp, erp.iloc[-1], invert=False)

            # [f6] Êù†ÊùÜËµÑÈáë (‰ΩøÁî®‰∏ä‰∫§ÊâÄÊï∞ÊçÆ)
            f6 = 50.0
            if not _df_margin.empty:
                cut_m = _df_margin[_df_margin['date_key'] <= target_date].copy()
                if not cut_m.empty and 'rzye' in cut_m.columns:
                    m_val = pd.to_numeric(cut_m['rzye'], errors='coerce')
                    f6 = get_score(m_val, m_val.iloc[-1], invert=False)

            return [round(x, 2) for x in [f1, f2, f3, f4, f5, f6]]
        except Exception as e:
            log(f"Âõ†Â≠êËÆ°ÁÆóÂá∫Èîô: {e}")
            return [50.0] * 6

    # --- 3. ÈáçÂª∫ÂéÜÂè≤ ---
    log("ÂºÄÂßãËÆ°ÁÆóÂéÜÂè≤‰∏éÈ¢ÑÊµã...")
    cols = ["date", "f1", "f2", "f3", "f4", "f5", "f6", "predict", "actual", "bias"]
    df_log = pd.DataFrame(columns=cols)

    for i in range(14, 0, -1):
        d = today - timedelta(days=i)
        if not is_workday(d): continue
        
        fs = calculate_factors(d, df_p, df_fut, df_val, df_bond, df_margin)
        p_raw = round(sum(fs) / 6, 2)
        act = get_actual_val(d)
        bias = round(act - p_raw, 2) if act is not None else np.nan
        df_log.loc[len(df_log)] = [d.strftime("%Y-%m-%d")] + fs + [p_raw, act, bias]

    # --- 4. ÊùÉÈáç‰ºòÂåñ ---
    weights = np.array([1/6] * 6)
    df_fit = df_log.dropna(subset=['actual']).tail(10)
    if len(df_fit) >= 5:
        X = df_fit[['f1', 'f2', 'f3', 'f4', 'f5', 'f6']].values
        y = df_fit['actual'].values
        res = minimize(lambda w: np.sum((X @ w - y)**2), weights, bounds=[(0.05, 0.4)]*6, constraints={'type':'eq','fun':lambda w: sum(w)-1})
        if res.success: weights = res.x

    # --- 5. ‰ªäÊó•ÁªìÊûú ---
    today_fs = calculate_factors(today, df_p, df_fut, df_val, df_bond, df_margin)
    today_raw = round(sum(f * w for f, w in zip(today_fs, weights)), 2)
    
    bias_fix = 0.0
    if not df_fit.empty:
        last_biases = df_fit['bias'].ewm(alpha=0.5).mean()
        bias_fix = last_biases.iloc[-1]
        if np.isnan(bias_fix): bias_fix = 0.0
    
    final_predict = round(today_raw + bias_fix, 2)

    # ‰øùÂ≠ò
    t_str = today.strftime("%Y-%m-%d")
    df_log = df_log[df_log['date'] != t_str]
    df_log.loc[len(df_log)] = [t_str] + today_fs + [today_raw, np.nan, np.nan]
    df_log.sort_values('date').to_csv(LOG_FILE, index=False)
    log(f"‚úÖ ËÆ°ÁÆóÂÆåÊàêÔºå‰ªäÊó•È¢ÑÊµã: {final_predict}")

    # --- 6. È£û‰π¶Êé®ÈÄÅ ---
    w_info = " | ".join([f"{n}:{w:.0%}" for n, w in zip(["Ê≥¢Âä®","ÈáèËÉΩ","Âº∫Â∫¶","ÊúüÁé∞","ËÇ°ÂÄ∫","Êù†ÊùÜ"], weights)])
    color_template = "red" if final_predict > 80 else ("green" if final_predict < 20 else "purple")
    
    payload = {
        "msg_type": "interactive",
        "card": {
            "header": {"title": {"tag": "plain_text", "content": f"üéØ ÊÅêË¥™ AI ÂÆûÁõòÈ¢ÑÊµã ({today})"}, "template": color_template},
            "elements": [
                {"tag": "div", "text": {"tag": "lark_md", "content": f"**‰ªäÊó•Âª∫ËÆÆÂÄºÔºö{final_predict}**\nÂéüÁîüÂàÜÔºö{today_raw} | ‰øÆÊ≠£Ôºö{bias_fix:+.1f}\n\nüìä **Âõ†Â≠êËØ¶ÊÉÖ (AkShareÂÆûÊó∂)**:\nüåä Ê≥¢Âä®: {today_fs[0]} | üîã ÈáèËÉΩ: {today_fs[1]}\nüí™ Âº∫Â∫¶: {today_fs[2]} | ‚öñÔ∏è ÊúüÁé∞: {today_fs[3]}\nüõ°Ô∏è ËÇ°ÂÄ∫: {today_fs[4]} | üé∞ Êù†ÊùÜ: {today_fs[5]}\n\nüß† **AI ÊùÉÈáçÈÖçÁΩÆ**:\n{w_info}"}},
                {"tag": "note", "elements": [{"tag": "plain_text", "content": "ÂÖ≥ÈîÆËØç: ÊÅêË¥™"}]}
            ]
        }
    }
    if FEISHU_WEBHOOK:
        try: requests.post(FEISHU_WEBHOOK, json=payload)
        except: pass

if __name__ == "__main__":
    main()